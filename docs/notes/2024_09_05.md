# ASR Model
- Following the recent results of the [Dutch Open Speech Recognition Benchmark](https://opensource-spraakherkenning-nl.github.io/ASR_NL_results/), there are a few models that we could use for ASR purposes. However, [Whisper](https://github.com/linto-ai/whisper-timestamped) seems to be the first choice for now, due to its lower WER in regular conversational dialogue in comparison to other models like Kaldi_NL and MMS.
- [faster-whisper](https://github.com/SYSTRAN/faster-whisper/) fits our use case well, as it lowers the computational time noticeably while maintaining (or even improving) WER. Specifically, faster-whisper v2 with VAD seems to produce to the lowest WER scores with the a relatively lower computation time (for speakers of Dutch).
  - faster-whisper has introduced a [Batching](https://github.com/SYSTRAN/faster-whisper/pull/856) strategy that allows for even faster computations.
- [WhisperLive](https://github.com/collabora/WhisperLive) offers a pre-made frontend and backend for a Whisper-based application, which could be useful if the Demonstrator has to interact with a server.

# TTS Model
- [MMS TTS](https://huggingface.co/facebook/mms-tts-nld) is a collection of Text-to-Speech models from Meta's MMS project and offers Dutch language TTS and is based on the VITS architecture.
- [XTTS](https://huggingface.co/coqui/XTTS-v2) is a TTS model that clones a voice based on a 6-second audio clip and supports Dutch language TTS.

# MT Model
- [Inseq](https://github.com/inseq-team/inseq) ([paper](https://aclanthology.org/2023.acl-demo.40/)) is a library for eXplainable Machine Translation produced by one of the CLST's partners, which we could use in order to translate Dutch into English and vice versa and explain that translation. The explainability method provided by Inseq is visual, however, so that would have to be translated into something that can be spoken aloud.

# Text Generators
- We use an ASR model for processing speech and a TTS model for producing speech, but we must also think about a model that is capable of generating a response once we want to make the Demonstrator conversational.
  - The first version of the Demonstrator excludes any text generators, and should only parrot the string that it heard.
  - Once that works, we can move on to using a text generator to generate responses.
  - LLMs that we may consider are Llama, Mistral, and Bloom.

# XAI
- [Prediction Overconfidence Deep Neural Network](https://www.google.com/search?q=prediction+overconfidence+deep+neural+network)

# Other
- The Demonstrator should be allowed and able to give fun(ny) answers as to engage the audience more.